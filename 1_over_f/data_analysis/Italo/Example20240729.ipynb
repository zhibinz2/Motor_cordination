{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import rqa_functions as rqa\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Italo/correlation_distances/dyad_20221003_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220713_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220816_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20221005_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_2022100401_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220810_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_2022100402_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220811_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220721_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220808_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220815_distances.pkl\n",
      "/data/Italo/correlation_distances/dyad_20220804_distances.pkl\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where the files are located\n",
    "directory_path = \"/data/Italo/correlation_distances\"\n",
    "\n",
    "# List all files and directories in the specified path\n",
    "all_items = os.listdir(directory_path)\n",
    "\n",
    "# Filter out files that start with \"dyad_20\"\n",
    "matching_files = [filename for filename in all_items if filename.startswith(\"dyad_20\")]\n",
    "\n",
    "# Optionally, get the full paths if needed\n",
    "full_paths = [os.path.join(directory_path, filename) for filename in matching_files]\n",
    "\n",
    "# Print the list of matching file paths\n",
    "for file_path in full_paths:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices_to_eliminate(subj1, subj2):\n",
    "    \"\"\"\n",
    "    Calculate the indices to be eliminated based on the differences in trial data points\n",
    "    for two subjects, ensuring that only the necessary data points are removed to align their sizes.\n",
    "\n",
    "    Parameters:\n",
    "    - list_indices_subj1: Numpy array of trial sizes for subject 1\n",
    "    - list_indices_subj2: Numpy array of trial sizes for subject 2\n",
    "\n",
    "    Returns:\n",
    "    - index_to_eliminate_subj1: Indices to eliminate from subject 1 to align with subject 2\n",
    "    - index_to_eliminate_subj2: Indices to eliminate from subject 2 to align with subject 1\n",
    "    \"\"\"\n",
    "\n",
    "    list_indices_subj1 = np.array([i[1] for i in subj1])\n",
    "    list_indices_subj2 = np.array([i[1] for i in subj2])\n",
    "\n",
    "    cumsum_subj1 = [sum([x[1] for x in subj1[:i+1]]) for i in range(len(subj1))]\n",
    "    cumsum_subj2 = [sum([x[1] for x in subj2[:i+1]]) for i in range(len(subj2))]\n",
    "\n",
    "    index_differences_sub1 = list_indices_subj1 - list_indices_subj2\n",
    "    index_differences_sub2 = list_indices_subj2 - list_indices_subj1\n",
    "\n",
    "    index_to_eliminate_subj1 = []\n",
    "    for i,n_points in enumerate(index_differences_sub1):\n",
    "        if n_points>0:\n",
    "            indexes = [j for j in range(cumsum_subj1[i]-index_differences_sub1[i],cumsum_subj1[i])]\n",
    "            index_to_eliminate_subj1.extend(indexes)\n",
    "\n",
    "    index_to_eliminate_subj2 = []\n",
    "    for i,n_points in enumerate(index_differences_sub2):\n",
    "        if n_points>0:\n",
    "            indexes = [j for j in range(cumsum_subj2[i]-index_differences_sub2[i],cumsum_subj2[i])]\n",
    "            index_to_eliminate_subj2.extend(indexes)\n",
    "\n",
    "    return index_to_eliminate_subj1[::-1], index_to_eliminate_subj2[::-1]\n",
    "\n",
    "def session_data_loading(file_path):\n",
    "\n",
    "    session = (file_path.split('/')[-1]).split('_')[1]\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Load the object from the pickle file\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    subj1 = data['subj1']['sizes']\n",
    "    subj2 = data['subj2']['sizes']\n",
    "\n",
    "    index_to_eliminate_subj1, index_to_eliminate_subj2 = find_indices_to_eliminate(subj1, subj2)\n",
    "\n",
    "    file_order_size = []\n",
    "    for i in range(len(subj1)):\n",
    "        file_sub1,len_1 = subj1[i]\n",
    "        file_sub2,len_2 = subj2[i]\n",
    "        if len_1 < len_2:\n",
    "            file_order_size.append((file_sub1,file_sub2,len_1))\n",
    "        else:\n",
    "            file_order_size.append((file_sub1,file_sub2,len_2))\n",
    "\n",
    "    mat1 = data['subj1']['distances']\n",
    "    for index in index_to_eliminate_subj1:\n",
    "        mat1 = np.delete(np.delete(mat1, index, axis=0), index, axis=1)\n",
    "\n",
    "    mat2 = data['subj2']['distances']\n",
    "    for index in index_to_eliminate_subj2:\n",
    "        mat2 = np.delete(np.delete(mat2, index, axis=0), index, axis=1)\n",
    "\n",
    "    trial_len = [i[2] for i in file_order_size]\n",
    "    start_points = list(np.cumsum(trial_len))\n",
    "    end_points = [i-1 for i in start_points]\n",
    "    start_points.insert(0,0)\n",
    "    start_points.pop(-1)\n",
    "    #print(start_points)\n",
    "    #print(end_points)\n",
    "    start_stop = list(zip(start_points,end_points))\n",
    "    #print(start_stop)\n",
    "\n",
    "    condition_dictionary = {1: 'Uncoupled', 2: '1_lead', 3: '2_lead', 4: 'Mutual'}\n",
    "    type_dictionary = {1: 'Synchronization', 2: 'Syncopation'}\n",
    "\n",
    "    # Initialize an empty list to store each row's data as a dictionary\n",
    "    data = []\n",
    "\n",
    "    for i, entry in enumerate(file_order_size):\n",
    "        session = entry[0].split('/')[0]\n",
    "        trial = entry[0].split('_')[2][:-4]\n",
    "        length = entry[2]\n",
    "        start, stop = start_stop[i]\n",
    "        filename = '/data/Italo/finger_tapping_behavioral_data/clean_' + str(session) + '_bpchan.mat'\n",
    "        beh_data = loadmat(filename)\n",
    "        conditions = list(beh_data['conditions'][0])\n",
    "        condition = condition_dictionary[conditions[int(trial)-1]]\n",
    "        session_type = type_dictionary[beh_data['session'][0][0]]\n",
    "\n",
    "        # Instead of printing, store the data in a dictionary\n",
    "        row_data = {\n",
    "            'session': session,\n",
    "            'session_type': session_type,\n",
    "            'condition': condition,\n",
    "            'trial': trial,\n",
    "            'start': start,\n",
    "            'stop': stop\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    metadata = pd.DataFrame(data)\n",
    "    session_data = {'Subject 1': mat1,\n",
    "                    'Subject 2': mat2,\n",
    "                    'Metadata': metadata,\n",
    "                    'Session Type': session_type}\n",
    "    return session, session_data\n",
    "\n",
    "def transform_tuples_to_symbols(tuple_sequence):\n",
    "    \"\"\"\n",
    "    Transforms a sequence of tuples into a sequence of unique symbols (integer numbers).\n",
    "    \n",
    "    Parameters:\n",
    "    - tuple_sequence: A sequence (e.g., list) of tuples.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of integers representing the sequence of symbols.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a mapping from each unique tuple to a unique integer\n",
    "    unique_tuples = set(tuple_sequence)  # Find all unique tuples\n",
    "    tuple_to_symbol_map = {t: i for i, t in enumerate(unique_tuples)}\n",
    "    \n",
    "    # Step 2: Transform the original sequence of tuples using the map\n",
    "    symbol_sequence = [tuple_to_symbol_map[t] for t in tuple_sequence]\n",
    "    \n",
    "    return symbol_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = {}\n",
    "for file_path in full_paths:\n",
    "    session,data = session_data_loading(file_path)\n",
    "    session_data[session] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file(filename):\n",
    "    \"\"\"\n",
    "    Load a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The path to the pickle file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    - The Python object loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' was not found.\")\n",
    "    except EOFError:\n",
    "        print(f\"Error: The file '{filename}' may be corrupted or empty.\")\n",
    "    except pickle.UnpicklingError:\n",
    "        print(f\"Error: The file '{filename}' could not be unpickled. It may not be a valid pickle file or may be corrupted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "session_clusterings = load_pickle_file('./clustering_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>Session Type</th>\n",
       "      <th>Condition</th>\n",
       "      <th>vmean</th>\n",
       "      <th>vvar</th>\n",
       "      <th>dmean</th>\n",
       "      <th>dvar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221003</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Uncoupled</td>\n",
       "      <td>2.877586</td>\n",
       "      <td>1.231567</td>\n",
       "      <td>5.360656</td>\n",
       "      <td>161.525665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221003</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.749616</td>\n",
       "      <td>1.115495</td>\n",
       "      <td>6.355140</td>\n",
       "      <td>318.266399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221003</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.422680</td>\n",
       "      <td>0.292132</td>\n",
       "      <td>3.109375</td>\n",
       "      <td>68.972412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221003</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>3.294586</td>\n",
       "      <td>2.497614</td>\n",
       "      <td>5.825175</td>\n",
       "      <td>161.892513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221003</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.199438</td>\n",
       "      <td>0.159663</td>\n",
       "      <td>2.088889</td>\n",
       "      <td>0.080988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>20220804</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.201365</td>\n",
       "      <td>11.746193</td>\n",
       "      <td>639.955887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>20220804</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Uncoupled</td>\n",
       "      <td>2.769585</td>\n",
       "      <td>0.724175</td>\n",
       "      <td>3.606897</td>\n",
       "      <td>57.797194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>20220804</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>3.403207</td>\n",
       "      <td>2.412452</td>\n",
       "      <td>8.995098</td>\n",
       "      <td>532.897035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>20220804</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.629888</td>\n",
       "      <td>1.710783</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>278.065359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>20220804</td>\n",
       "      <td>Synchronization</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>3.745042</td>\n",
       "      <td>4.334430</td>\n",
       "      <td>12.230769</td>\n",
       "      <td>737.780079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Session     Session Type        Condition     vmean      vvar  \\\n",
       "0    20221003  Synchronization        Uncoupled  2.877586  1.231567   \n",
       "1    20221003  Synchronization  Leader-Follower  2.749616  1.115495   \n",
       "2    20221003  Synchronization           Mutual  2.422680  0.292132   \n",
       "3    20221003  Synchronization  Leader-Follower  3.294586  2.497614   \n",
       "4    20221003  Synchronization  Leader-Follower  2.199438  0.159663   \n",
       "..        ...              ...              ...       ...       ...   \n",
       "139  20220804  Synchronization  Leader-Follower  4.000000  3.201365   \n",
       "140  20220804  Synchronization        Uncoupled  2.769585  0.724175   \n",
       "141  20220804  Synchronization  Leader-Follower  3.403207  2.412452   \n",
       "142  20220804  Synchronization  Leader-Follower  2.629888  1.710783   \n",
       "143  20220804  Synchronization           Mutual  3.745042  4.334430   \n",
       "\n",
       "         dmean        dvar  \n",
       "0     5.360656  161.525665  \n",
       "1     6.355140  318.266399  \n",
       "2     3.109375   68.972412  \n",
       "3     5.825175  161.892513  \n",
       "4     2.088889    0.080988  \n",
       "..         ...         ...  \n",
       "139  11.746193  639.955887  \n",
       "140   3.606897   57.797194  \n",
       "141   8.995098  532.897035  \n",
       "142   6.666667  278.065359  \n",
       "143  12.230769  737.780079  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "recurrence_plots = {}\n",
    "\n",
    "for session_code in session_data:\n",
    "    mat1,mat2,metadata,session_type =  session_data[session_code].values()\n",
    "    sub1_seq,sub2_seq = session_clusterings[session_code]\n",
    "    joint_seq = list(zip(sub1_seq,sub2_seq))\n",
    "    joint_seq = transform_tuples_to_symbols(joint_seq)\n",
    "\n",
    "    start_list = list(metadata['start'])\n",
    "    stop_list = list(metadata['stop'])\n",
    "    start_stop = list(zip(start_list,stop_list))\n",
    "    conditions = list(metadata['condition'])\n",
    "\n",
    "    recurrence_matrix = rqa.build_rp(joint_seq)\n",
    "    recurrence_plots[session_code] = {'rp': recurrence_matrix,\n",
    "                                      'symbol_sequence': joint_seq}\n",
    "    for j,indices in enumerate(start_stop):\n",
    "        condition = conditions[j]\n",
    "        if condition == '1_lead' or condition == '2_lead':\n",
    "            condition = 'Leader-Follower'\n",
    "        start, stop = indices\n",
    "        \n",
    "        matrix = recurrence_matrix[start:stop,start:stop]\n",
    "\n",
    "        vlines = rqa.find_lines(matrix, min_len=2, direction='vertical')\n",
    "        vmean = np.mean(vlines)\n",
    "        vvar = np.var(vlines)\n",
    "        dlines = rqa.find_lines(matrix, min_len=2, direction='diagonal')\n",
    "        dmean = np.mean(dlines)\n",
    "        dvar = np.var(dlines)\n",
    "\n",
    "        df_row = {'Session': session_code,\n",
    "                'Session Type': session_type,\n",
    "                'Condition': condition,\n",
    "                'vmean': vmean,\n",
    "                'vvar': vvar,\n",
    "                'dmean': dmean,\n",
    "                'dvar': dvar}\n",
    "        data.append(df_row)\n",
    "\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
