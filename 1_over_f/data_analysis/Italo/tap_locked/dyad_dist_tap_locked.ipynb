{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import makefilter\n",
    "from scipy.signal import sosfiltfilt, hilbert\n",
    "from scipy.signal import savgol_filter\n",
    "import pickle\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_data_folders(directory_path,pattern):\n",
    "    \"\"\"\n",
    "    Lists all folders in the given directory that start with pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory_path: A string representing the path to the directory to search in.\n",
    "\n",
    "    - pattern: A string representing the pattern at the beginning of the folders' name.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of folder names that meet the criteria.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"The directory {directory_path} does not exist.\")\n",
    "        return []\n",
    "\n",
    "    # Get all items in the directory\n",
    "    all_items = os.listdir(directory_path)\n",
    "\n",
    "    # Filter for directories that start with pattern\n",
    "    folders_starting_with_pattern = [item for item in all_items\n",
    "                                if os.path.isdir(os.path.join(directory_path, item)) and item.startswith(pattern)]\n",
    "\n",
    "    return folders_starting_with_pattern\n",
    "\n",
    "def list_files_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Lists all the files in the specified directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory_path: A string representing the path to the directory to search in.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of file names contained in the directory.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"The directory {directory_path} does not exist.\")\n",
    "        return []\n",
    "\n",
    "    # Get all items in the directory\n",
    "    all_items = os.listdir(directory_path)\n",
    "\n",
    "    # Filter out only files\n",
    "    files_only = [item for item in all_items if os.path.isfile(os.path.join(directory_path, item))]\n",
    "\n",
    "    return files_only\n",
    "\n",
    "def open_mat_file(file_path):\n",
    "    \"\"\"\n",
    "    Opens a .mat file and returns its contents.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: A string representing the path to the .mat file.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing variables loaded from the .mat file.\n",
    "    \"\"\"\n",
    "    # Load the .mat file\n",
    "    data = loadmat(file_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def segment_time_series(data, segment_duration, overlap_duration, sampling_rate):\n",
    "    \"\"\"\n",
    "    Segments each time series in a 2D NumPy array into smaller time series segments \n",
    "    based on specified duration, overlap, and sampling rate.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy.ndarray): A 2D NumPy array containing the time series data. Each \n",
    "    column represents a single time series.\n",
    "    - segment_duration (float): The duration of each segment in seconds. Determines\n",
    "     the length of each segment generated.\n",
    "    - overlap_duration (float): The duration of overlap between consecutive segments\n",
    "     in seconds. This specifies how much each segment should overlap with the next.\n",
    "    - sampling_rate (int): The number of samples per second in the time series data.\n",
    "     This is used to calculate the number of samples per segment and the overlap in \n",
    "     samples.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: A 3D NumPy array where the 1st dimension represents a segmented portion \n",
    "    of the original time series. The 2nd dimension in this array equals the number \n",
    "    of samples per segment, determined by the `segment_duration` and `sampling_rate`.\n",
    "    \"\"\"\n",
    "    # Calculate parameters\n",
    "    samples_per_segment = int(segment_duration * sampling_rate)\n",
    "    overlap_samples = int(overlap_duration * sampling_rate)\n",
    "    step_size = samples_per_segment - overlap_samples\n",
    "    \n",
    "    segments = []\n",
    "    len_data,_ = data.shape\n",
    "    for start in range(0, len_data - samples_per_segment + 1, step_size):\n",
    "        segment = data[start:start+samples_per_segment,:]\n",
    "        segments.append(segment)\n",
    "            \n",
    "    return np.array(segments)\n",
    "\n",
    "def save_to_pickle(dict_obj, file_path):\n",
    "    \"\"\"\n",
    "    Saves a given dictionary to a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - dict_obj (dict): The dictionary to be saved.\n",
    "    - file_path (str): The path to the file where the dictionary will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    with open(file_path, 'wb') as file:\n",
    "        # Serialize the dictionary and save it to the file\n",
    "        pickle.dump(dict_obj, file)\n",
    "    print(f\"Data successfully saved to {file_path}.\")\n",
    "\n",
    "def corr_matrix_stack(corr_matrix_dic):\n",
    "    \"\"\"\n",
    "    Stacks correlation matrices along axis 0 and tracks their sizes and identifiers.\n",
    "\n",
    "    This function takes a dictionary of correlation matrices (2D NumPy arrays) and\n",
    "    stacks these matrices vertically. It also compiles a list of the sizes of these\n",
    "    matrices along axis 0, alongside their identifiers.\n",
    "\n",
    "    Parameters:\n",
    "    - corr_matrix_dic (dict): A dictionary where the keys are identifiers (e.g., file names)\n",
    "      and the values are correlation matrices (2D NumPy arrays). Each matrix is assumed to\n",
    "      have the same number of columns but can vary in the number of rows.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: A single 2D NumPy array resulting from stacking all the input matrices\n",
    "      along axis 0.\n",
    "    - list of tuples: Each tuple contains an identifier (key from the input dictionary) and\n",
    "      an integer representing the size (number of rows) of the corresponding matrix before\n",
    "      stacking. This list maintains the order in which matrices were stacked.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to keep track of each matrix's identifier and its number of rows\n",
    "    size_matrices = []\n",
    "    \n",
    "    # Initialize a list to hold all matrices for concatenation\n",
    "    matrix_list = []\n",
    "    \n",
    "    # Iterate over the dictionary items\n",
    "    for file, matrix in corr_matrix_dic.items():\n",
    "        # Append each matrix to the list for later concatenation\n",
    "        matrix_list.append(matrix)\n",
    "        # Append a tuple of the matrix's identifier and its number of rows to the tracking list\n",
    "        size_matrices.append((file, matrix.shape[0]))\n",
    "    \n",
    "    # Concatenate all matrices vertically\n",
    "    stacked_array = np.concatenate(matrix_list, axis=0)\n",
    "    \n",
    "    # Return the stacked array and the list of identifiers with their corresponding matrix sizes\n",
    "    return stacked_array, size_matrices\n",
    "\n",
    "def corr_dist(A,B):\n",
    "    from scipy.linalg import norm\n",
    "    D = np.transpose(np.conj(A))@B\n",
    "    dist = np.real(np.log(1.0/(np.trace(D)/(norm(A)*norm(B)))))\n",
    "    return dist\n",
    "\n",
    "def sort_key(filename):\n",
    "    trial_part = int(filename.split('_')[-1].split('.')[0])  # Extract the trial number\n",
    "    return trial_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_time_series_taplocked(data, segment_duration, sampling_rate, tr_samples):\n",
    "    \"\"\"\n",
    "    Segments each time series in a 2D NumPy array into smaller time series segments \n",
    "    based on specified duration, and sampling rate.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy.ndarray): A 2D NumPy array containing the time series data. Each \n",
    "    column represents a single time series.\n",
    "    - segment_duration (float): The duration of each segment in seconds. Determines\n",
    "     the length of each segment generated.\n",
    "    - sampling_rate (int): The number of samples per second in the time series data.\n",
    "     This is used to calculate the number of samples per segment and the overlap in \n",
    "     samples.\n",
    "    - tr_samples: index of taps in the samples of a single trial\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: A 3D NumPy array where the 1st dimension represents a segmented portion \n",
    "    of the original time series. The 2nd dimension in this array equals the number \n",
    "    of samples per segment, determined by the `segment_duration` and `sampling_rate`.\n",
    "    \"\"\"\n",
    "    # Calculate parameters\n",
    "    samples_per_segment = int(segment_duration * sampling_rate)\n",
    "\n",
    "    segments = []\n",
    "    for start in tr_samples:\n",
    "        segment = data[start-samples_per_segment:start,:]\n",
    "        segments.append(segment)\n",
    "\n",
    "    return np.array(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_path = '/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/'  # Replace this with the path to your directory\n",
    "# folders = list_data_folders(directory_path,'20')\n",
    "\n",
    "#Butterworth filters.\n",
    "butt_filter1,butt_w,butt_h = makefilter.makefiltersos(2000,50,60)\n",
    "# window_len = 2.0\n",
    "window_len = 0.5\n",
    "# overlap = 0.5\n",
    "# overlap_len = overlap*window_len\n",
    "butt_filter2,butt_w,butt_h = makefilter.makefiltersos(2000,1.0/window_len,0.5/window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['20220713','20220721',\n",
    "           '20220804','20220808',\n",
    "           '20220810','20220811',\n",
    "           '20220815','20220816',\n",
    "           '20221003','2022100401',\n",
    "           '2022100402','20221005']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=folders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220713\n"
     ]
    }
   ],
   "source": [
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/' + folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/20220713'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files_in_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subj1_tr_8.mat',\n",
       " 'subj1_tr_4.mat',\n",
       " 'subj2_tr_4.mat',\n",
       " 'subj2_tr_9.mat',\n",
       " 'subj1_tr_11.mat',\n",
       " 'subj1_tr_5.mat',\n",
       " 'subj1_tr_1.mat',\n",
       " 'subj1_tr_10.mat',\n",
       " 'subj1_tr_3.mat',\n",
       " 'subj2_tr_2.mat',\n",
       " 'subj2_tr_1.mat',\n",
       " 'subj1_tr_6.mat',\n",
       " 'subj1_tr_9.mat',\n",
       " 'subj2_tr_6.mat',\n",
       " 'subj2_tr_3.mat',\n",
       " 'subj2_tr_12.mat',\n",
       " 'subj1_tr_7.mat',\n",
       " 'subj2_tr_8.mat',\n",
       " 'subj2_tr_11.mat',\n",
       " 'subj1_tr_2.mat',\n",
       " 'subj2_tr_7.mat',\n",
       " 'subj2_tr_5.mat',\n",
       " 'subj1_tr_12.mat',\n",
       " 'subj2_tr_10.mat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load event time points\n",
    "beha_filename = '/home/zhibinz2/Documents/GitHub/finger_tapping_behavioral_data/clean_' + str(folder) + '_bpchan.mat'\n",
    "beh_data =  loadmat(beha_filename)\n",
    "samples = beh_data['samples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference(error) of the samples\n",
    "tr=0\n",
    "tr_samples = samples[tr]\n",
    "num_tp=len(tr_samples)\n",
    "tr_error=np.zeros(num_tp)\n",
    "for tp in range(num_tp):\n",
    "    tr_error[tp]=np.abs(tr_samples[tp][0]-tr_samples[tp][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files listed.\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    subject, rest = filename.split('_', 1)\n",
    "    if subject not in files_dic:\n",
    "        files_dic[subject] = {}\n",
    "    file = folder + '/' + filename\n",
    "    files_dic[subject][filename] = directory_path + '/' + filename\n",
    "print('files listed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['subj1_tr_8.mat', 'subj1_tr_4.mat', 'subj1_tr_11.mat', 'subj1_tr_5.mat', 'subj1_tr_1.mat', 'subj1_tr_10.mat', 'subj1_tr_3.mat', 'subj1_tr_6.mat', 'subj1_tr_9.mat', 'subj1_tr_7.mat', 'subj1_tr_2.mat', 'subj1_tr_12.mat'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dic['subj1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['subj2_tr_4.mat', 'subj2_tr_9.mat', 'subj2_tr_2.mat', 'subj2_tr_1.mat', 'subj2_tr_6.mat', 'subj2_tr_3.mat', 'subj2_tr_12.mat', 'subj2_tr_8.mat', 'subj2_tr_11.mat', 'subj2_tr_7.mat', 'subj2_tr_5.mat', 'subj2_tr_10.mat'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dic['subj2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_matrices = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject='subj1'\n",
    "subj=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj1\n"
     ]
    }
   ],
   "source": [
    "print(subject) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrices = {}\n",
    "subject_files = list(files_dic[subject].keys())\n",
    "subject_files = sorted(subject_files,key=sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subj1_tr_1.mat',\n",
       " 'subj1_tr_2.mat',\n",
       " 'subj1_tr_3.mat',\n",
       " 'subj1_tr_4.mat',\n",
       " 'subj1_tr_5.mat',\n",
       " 'subj1_tr_6.mat',\n",
       " 'subj1_tr_7.mat',\n",
       " 'subj1_tr_8.mat',\n",
       " 'subj1_tr_9.mat',\n",
       " 'subj1_tr_10.mat',\n",
       " 'subj1_tr_11.mat',\n",
       " 'subj1_tr_12.mat']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20220713/subj1_tr_1.mat'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr=1\n",
    "file='subj1_tr_1.mat'\n",
    "path = files_dic[subject][file]\n",
    "filename = folder + '/' + file\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/20220713/subj1_tr_1.mat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data from a sample file.\n",
    "data = open_mat_file(path)\n",
    "#Get signal, filter and downsample.\n",
    "signal = data['agr_source_data']\n",
    "filtered_signal = sosfiltfilt(butt_filter1, signal, axis=0)\n",
    "filtered_signal = sosfiltfilt(butt_filter2, filtered_signal, axis=0)\n",
    "# downsampled_signal = filtered_signal[::10,:]\n",
    "# analytic_signal = hilbert(downsampled_signal,axis=0)\n",
    "# no downsampling\n",
    "analytic_signal = hilbert(filtered_signal,axis=0)\n",
    "sg = int(np.floor(100/(25))*2+1)\n",
    "ts1 = savgol_filter(np.real(analytic_signal),sg,1,axis = 0,mode = 'interp')\n",
    "ts2 = savgol_filter(np.imag(analytic_signal),sg,1,axis = 0,mode = 'interp')\n",
    "ts3 = ts1+1j*ts2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_windows = segment_time_series(ts3, window_len, overlap_len, 200)\n",
    "# segment data with tap-locked windows\n",
    "tr_samples_subj = samples[tr][:,subj]\n",
    "time_windows = segment_time_series_taplocked(ts3, window_len, 2000, tr_samples_subj)\n",
    "# 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 448)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(time_windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = []\n",
    "for window in time_windows:\n",
    "    corr_matrix.append(np.corrcoef(window, rowvar=False))\n",
    "corr_matrix = np.array(corr_matrix)\n",
    "corr_matrix = corr_matrix - np.mean(corr_matrix,axis=0)\n",
    "corr_matrices[filename] = corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "subj1_tr_1.mat\n",
      "1\n",
      "subj1_tr_2.mat\n",
      "2\n",
      "subj1_tr_3.mat\n",
      "3\n",
      "subj1_tr_4.mat\n",
      "4\n",
      "subj1_tr_5.mat\n",
      "5\n",
      "subj1_tr_6.mat\n",
      "6\n",
      "subj1_tr_7.mat\n",
      "7\n",
      "subj1_tr_8.mat\n",
      "8\n",
      "subj1_tr_9.mat\n",
      "9\n",
      "subj1_tr_10.mat\n",
      "10\n",
      "subj1_tr_11.mat\n",
      "11\n",
      "subj1_tr_12.mat\n",
      "correlation matrices calculated.\n"
     ]
    }
   ],
   "source": [
    "for tr, file in enumerate(subject_files):\n",
    "    print(tr)\n",
    "    print(file)\n",
    "    path = files_dic[subject][file]\n",
    "    filename = folder + '/' + file\n",
    "    # print(path)\n",
    "    #Import the data from a sample file.\n",
    "    data = open_mat_file(path)\n",
    "    #Get signal, filter and downsample.\n",
    "    signal = data['agr_source_data']\n",
    "    filtered_signal = sosfiltfilt(butt_filter1, signal, axis=0)\n",
    "    filtered_signal = sosfiltfilt(butt_filter2, filtered_signal, axis=0)\n",
    "    # downsampled_signal = filtered_signal[::10,:]\n",
    "    # analytic_signal = hilbert(downsampled_signal,axis=0)\n",
    "    # no downsampling\n",
    "    analytic_signal = hilbert(filtered_signal,axis=0)\n",
    "    sg = int(np.floor(100/(25))*2+1)\n",
    "    ts1 = savgol_filter(np.real(analytic_signal),sg,1,axis = 0,mode = 'interp')\n",
    "    ts2 = savgol_filter(np.imag(analytic_signal),sg,1,axis = 0,mode = 'interp')\n",
    "    ts3 = ts1+1j*ts2\n",
    "    \n",
    "    # time_windows = segment_time_series(ts3, window_len, overlap_len, 200)\n",
    "    # segment data with tap-locked windows\n",
    "    tr_samples = samples[tr][:,subj]\n",
    "    time_windows = segment_time_series_taplocked(ts3, window_len, 2000, tr_samples)\n",
    "\n",
    "    corr_matrix = []\n",
    "    for window in time_windows:\n",
    "        corr_matrix.append(np.corrcoef(window, rowvar=False))\n",
    "    corr_matrix = np.array(corr_matrix)\n",
    "    corr_matrix = corr_matrix - np.mean(corr_matrix,axis=0)\n",
    "    corr_matrices[filename] = corr_matrix\n",
    "print('correlation matrices calculated.')\n",
    "# 9 min for 12 files in one subject\n",
    "# 9 x 12 files x 2 subjects x 12 session = 43 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix,sizes = corr_matrix_stack(corr_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['20220713/subj1_tr_1.mat', '20220713/subj1_tr_2.mat', '20220713/subj1_tr_3.mat', '20220713/subj1_tr_4.mat', '20220713/subj1_tr_5.mat', '20220713/subj1_tr_6.mat', '20220713/subj1_tr_7.mat', '20220713/subj1_tr_8.mat', '20220713/subj1_tr_9.mat', '20220713/subj1_tr_10.mat', '20220713/subj1_tr_11.mat', '20220713/subj1_tr_12.mat'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20220713/subj1_tr_1.mat', 128),\n",
       " ('20220713/subj1_tr_2.mat', 148),\n",
       " ('20220713/subj1_tr_3.mat', 124),\n",
       " ('20220713/subj1_tr_4.mat', 116),\n",
       " ('20220713/subj1_tr_5.mat', 145),\n",
       " ('20220713/subj1_tr_6.mat', 146),\n",
       " ('20220713/subj1_tr_7.mat', 114),\n",
       " ('20220713/subj1_tr_8.mat', 141),\n",
       " ('20220713/subj1_tr_9.mat', 132),\n",
       " ('20220713/subj1_tr_10.mat', 140),\n",
       " ('20220713/subj1_tr_11.mat', 145),\n",
       " ('20220713/subj1_tr_12.mat', 147)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1626, 448, 448)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = np.zeros((len(matrix),len(matrix)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in combinations(range(len(matrix)),2):\n",
    "    print(i)\n",
    "    matrix1 = matrix[i,:,:]\n",
    "    matrix2 = matrix[j,:,:]\n",
    "    dist_matrix[i,j] = corr_dist(matrix1,matrix2)\n",
    "    dist_matrix[j,i] = dist_matrix[i,j]\n",
    "        \n",
    "print('distance matrices calculated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_matrices[subject] = {'distances': dist_matrix, 'sizes':sizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_matrices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_matrices['subj1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(subject_matrices['subj1']['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_matrices['subj1']['sizes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022100401\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(folder)\n",
    "    files_dic = {}\n",
    "#    for folder in folders:\n",
    "#    folder_dic = {}\n",
    "    directory_path = '/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/' + folder\n",
    "    files = list_files_in_directory(directory_path)\n",
    "\n",
    "    # load event time points\n",
    "    beha_filename = '/home/zhibinz2/Documents/GitHub/finger_tapping_behavioral_data/clean_' + str(folder) + '_bpchan.mat'\n",
    "    beh_data =  loadmat(beha_filename)\n",
    "    samples = beh_data['samples'][0]\n",
    "\n",
    "    for filename in files:\n",
    "        subject, rest = filename.split('_', 1)\n",
    "        if subject not in files_dic:\n",
    "            files_dic[subject] = {}\n",
    "        file = folder + '/' + filename\n",
    "        files_dic[subject][filename] = directory_path + '/' + filename\n",
    "    print('files listed.')\n",
    "\n",
    "    subject_matrices = {}\n",
    "    for subj,subject in enumerate(['subj1','subj2']):\n",
    "        print(subj)\n",
    "        print(subject) \n",
    "        corr_matrices = {}\n",
    "        subject_files = list(files_dic[subject].keys())\n",
    "        subject_files = sorted(subject_files,key=sort_key)\n",
    "        \n",
    "\n",
    "        for tr, file in enumerate(subject_files):\n",
    "            print(tr)\n",
    "            print(file)\n",
    "            path = files_dic[subject][file]\n",
    "            filename = folder + '/' + file\n",
    "            # print(path)\n",
    "\n",
    "            #Import the data from a sample file.\n",
    "            data = open_mat_file(path)\n",
    "\n",
    "            #Get signal, filter and downsample.\n",
    "            signal = data['agr_source_data']\n",
    "            filtered_signal = sosfiltfilt(butt_filter1, signal, axis=0)\n",
    "            filtered_signal = sosfiltfilt(butt_filter2, filtered_signal, axis=0)\n",
    "            # downsampled_signal = filtered_signal[::10,:]\n",
    "            # analytic_signal = hilbert(downsampled_signal,axis=0)\n",
    "            # no downsampling\n",
    "            analytic_signal = hilbert(filtered_signal,axis=0)\n",
    "\n",
    "            sg = int(np.floor(100/(25))*2+1)\n",
    "            ts1 = savgol_filter(np.real(analytic_signal),sg,1,axis = 0,mode = 'interp')\n",
    "            ts2 = savgol_filter(np.imag(analytic_signal),sg,1,axis = 0,mode = 'interp')\n",
    "            ts3 = ts1+1j*ts2\n",
    "            \n",
    "            # time_windows = segment_time_series(ts3, window_len, overlap_len, 200)\n",
    "            # segment data with tap-locked windows\n",
    "            tr_samples = samples[tr][:,subj]\n",
    "            time_windows = segment_time_series_taplocked(ts3, window_len, 2000,tr_samples)\n",
    "            \n",
    "            corr_matrix = []\n",
    "            for window in time_windows:\n",
    "                corr_matrix.append(np.corrcoef(window, rowvar=False))\n",
    "            corr_matrix = np.array(corr_matrix)\n",
    "            corr_matrix = corr_matrix - np.mean(corr_matrix,axis=0)\n",
    "            corr_matrices[filename] = corr_matrix\n",
    "        print('correlation matrices calculated.')\n",
    "\n",
    "        matrix,sizes = corr_matrix_stack(corr_matrices)\n",
    "        dist_matrix = np.zeros((len(matrix),len(matrix)))\n",
    "        for i,j in combinations(range(len(matrix)),2):\n",
    "            print(i)\n",
    "            matrix1 = matrix[i,:,:]\n",
    "            matrix2 = matrix[j,:,:]\n",
    "            dist_matrix[i,j] = corr_dist(matrix1,matrix2)\n",
    "            dist_matrix[j,i] = dist_matrix[i,j]\n",
    "        \n",
    "        print('distance matrices calculated.')\n",
    "        subject_matrices[subject] = {'distances': dist_matrix, 'sizes':sizes}\n",
    "    \n",
    "    # filename_save = '/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/Italo/correlation_distances/dyad_' + folder + '_distances.pkl'\n",
    "    filename_save = '/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_' + folder + '_distances.pkl'\n",
    "    print(filename_save)\n",
    "    save_to_pickle(subject_matrices, filename_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/2022100401/subj1_tr_6.mat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_mat_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tr12'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20220713',\n",
       " '20220721',\n",
       " '20220804',\n",
       " '20220808',\n",
       " '20220810',\n",
       " '20220811',\n",
       " '20220815',\n",
       " '20220816',\n",
       " '20221003',\n",
       " '2022100401',\n",
       " '2022100402',\n",
       " '20221005']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220713\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2168604/3717702527.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(segments)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220721\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220804\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220808\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220810\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220811\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220815\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20220816\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20221003\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "2022100401\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "2022100402\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n",
      "20221005\n",
      "files listed.\n",
      "subj1\n",
      "subj1_tr_1.mat\n",
      "subj1_tr_2.mat\n",
      "subj1_tr_3.mat\n",
      "subj1_tr_4.mat\n",
      "subj1_tr_5.mat\n",
      "subj1_tr_6.mat\n",
      "subj1_tr_7.mat\n",
      "subj1_tr_8.mat\n",
      "subj1_tr_9.mat\n",
      "subj1_tr_10.mat\n",
      "subj1_tr_11.mat\n",
      "subj1_tr_12.mat\n",
      "subj2\n",
      "subj2_tr_1.mat\n",
      "subj2_tr_2.mat\n",
      "subj2_tr_3.mat\n",
      "subj2_tr_4.mat\n",
      "subj2_tr_5.mat\n",
      "subj2_tr_6.mat\n",
      "subj2_tr_7.mat\n",
      "subj2_tr_8.mat\n",
      "subj2_tr_9.mat\n",
      "subj2_tr_10.mat\n",
      "subj2_tr_11.mat\n",
      "subj2_tr_12.mat\n"
     ]
    }
   ],
   "source": [
    "# compute and save errors\n",
    "errors={}\n",
    "for folder in folders:\n",
    "    errors_folder={}   \n",
    "    print(folder)\n",
    "    files_dic = {}\n",
    "#    for folder in folders:\n",
    "#    folder_dic = {}\n",
    "    directory_path = '/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/' + folder\n",
    "    files = list_files_in_directory(directory_path)\n",
    "\n",
    "    # load event time points\n",
    "    beha_filename = '/home/zhibinz2/Documents/GitHub/finger_tapping_behavioral_data/clean_' + str(folder) + '_bpchan.mat'\n",
    "    beh_data =  loadmat(beha_filename)\n",
    "    samples = beh_data['samples'][0]\n",
    "\n",
    "    for filename in files:\n",
    "        subject, rest = filename.split('_', 1)\n",
    "        if subject not in files_dic:\n",
    "            files_dic[subject] = {}\n",
    "        file = folder + '/' + filename\n",
    "        files_dic[subject][filename] = directory_path + '/' + filename\n",
    "    print('files listed.')\n",
    "\n",
    "    for subj,subject in enumerate(['subj1','subj2']):\n",
    "        # print(subj)\n",
    "        print(subject) \n",
    "        corr_matrices = {}\n",
    "        subject_files = list(files_dic[subject].keys())\n",
    "        subject_files = sorted(subject_files,key=sort_key) \n",
    "\n",
    "        for tr, file in enumerate(subject_files):\n",
    "            # print(tr)\n",
    "            print(file)\n",
    "            path = files_dic[subject][file]\n",
    "            filename = folder + '/' + file\n",
    "            # print(path)\n",
    "\n",
    "            # time_windows = segment_time_series(ts3, window_len, overlap_len, 200)\n",
    "            # segment data with tap-locked windows\n",
    "            tr_samples = samples[tr][:,subj]\n",
    "            time_windows = segment_time_series_taplocked(ts3, window_len, 2000,tr_samples)\n",
    "\n",
    "            # Compute difference(error) of the samples\n",
    "            if subject == 'subj1':\n",
    "                tr_samples_both = samples[tr]\n",
    "                num_tp=len(tr_samples_both)\n",
    "                tr_error=np.zeros(num_tp)\n",
    "                for tp in range(num_tp):\n",
    "                    tr_error[tp]=np.abs(tr_samples_both[tp][0]-tr_samples_both[tp][1])\n",
    "                errors_folder[file.split('_')[1]+(file.split('_')[2]).split('.')[0]]=tr_error\n",
    "    \n",
    "    errors[folder]=errors_folder\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subj2_tr_1.mat',\n",
       " 'subj2_tr_2.mat',\n",
       " 'subj2_tr_3.mat',\n",
       " 'subj2_tr_4.mat',\n",
       " 'subj2_tr_5.mat',\n",
       " 'subj2_tr_6.mat',\n",
       " 'subj2_tr_7.mat',\n",
       " 'subj2_tr_8.mat',\n",
       " 'subj2_tr_9.mat',\n",
       " 'subj2_tr_10.mat',\n",
       " 'subj2_tr_11.mat',\n",
       " 'subj2_tr_12.mat']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tr1', 'tr2', 'tr3', 'tr4', 'tr5', 'tr6', 'tr7', 'tr8', 'tr9', 'tr10', 'tr11', 'tr12'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_folder.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([652., 550., 328., 244.,  97., 661., 686., 570., 459., 436., 336.,\n",
       "        96., 141., 516., 696., 644., 643., 210., 121., 473., 631., 664.,\n",
       "       715., 383.,  81., 185., 738., 499., 335.,  36., 253., 416., 739.,\n",
       "       482., 239., 364., 234., 345., 641., 597., 851., 666., 520., 492.,\n",
       "       561., 497., 573., 533., 559., 554., 509., 524., 500., 535., 647.,\n",
       "       707., 745., 720., 742., 814., 708., 615., 625., 463., 413., 852.,\n",
       "       551., 436., 344., 417., 501., 403., 488., 389., 303., 445., 546.,\n",
       "       513., 456., 473., 455., 452., 390., 325., 317., 358., 536., 425.,\n",
       "       222., 364., 473., 461., 485., 547., 611., 501., 505., 515., 489.,\n",
       "       525., 580., 494., 645., 781., 688., 680., 746., 800., 736., 748.,\n",
       "       655., 652., 558., 716., 609., 676., 578., 555., 453., 466., 651.,\n",
       "       614., 549., 494., 407., 681., 646., 677., 558., 644., 525., 581.,\n",
       "       382., 275., 196., 150., 271., 494., 563., 323., 318., 169., 101.,\n",
       "       355., 393., 326., 336., 470., 463., 434., 415., 593., 494., 381.,\n",
       "       399., 420., 359., 502., 399., 123., 157., 167., 103., 227., 173.,\n",
       "       403., 635., 566., 275., 147.,  43., 222., 100., 277., 238., 390.,\n",
       "       442., 276., 321.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_folder['tr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237., 200.,  73.,  72.,  61.,  35., 175.,  87., 124.,  74., 102.,\n",
       "       152., 205.,  75., 149.,  63.,  22.,  22.,  40.,  24.,  32.,  83.,\n",
       "       113.,  74.,  27.,   0.,  43.,  23., 103.,  73.,  51.,  45.,  61.,\n",
       "         3.,   8.,  23., 131., 108.,  87.,  13., 385., 353., 289., 244.,\n",
       "       333., 123.,  73.,  63.,  72.,  22.,   3.,  19.,   6.,  37.,  31.,\n",
       "        49.,  75.,  78.,  21.,  48.,  29.,  97., 109., 142.,  78., 321.,\n",
       "       203., 233.,  22.,   2., 169., 148.,  75.,  61.,  40.,  37.,  24.,\n",
       "        66.,  32.,  15.,  52.,  18., 134., 139., 131., 145.,  24.,  20.,\n",
       "        10., 103.,   1., 124.,   8.,  83., 142.,  70.,  71.,   2.,  93.,\n",
       "       141.,  53.,  43., 161., 185.,  48.,  60.,  95.,  69., 120., 212.,\n",
       "         2.,   3.,  53.,  53., 150., 236., 249., 185., 241., 219., 217.,\n",
       "       124.,  62., 233., 445., 211.,  94.,  28.,  34.,  64., 234., 194.,\n",
       "       185., 201., 302., 323., 453., 473., 198., 153., 168.,   9.,  93.,\n",
       "        11., 116.,  48., 216., 120., 245.,   8.,  31.,  64., 109., 195.,\n",
       "       142., 114., 165., 121., 274.,   7.,  93.,  68.,  59.,  57.,  27.,\n",
       "        58.,  17.,  31.,  61., 286., 324., 451., 171., 170., 251., 174.,\n",
       "        80., 137.,  37., 183., 151., 129., 171., 280., 169., 141.,  67.,\n",
       "       131., 178., 261., 176., 273., 155., 170., 146., 269., 304.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['20220713']['tr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf5storage import loadmat, savemat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20221005'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tr1': array([652., 550., 328., 244.,  97., 661., 686., 570., 459., 436., 336.,\n",
       "         96., 141., 516., 696., 644., 643., 210., 121., 473., 631., 664.,\n",
       "        715., 383.,  81., 185., 738., 499., 335.,  36., 253., 416., 739.,\n",
       "        482., 239., 364., 234., 345., 641., 597., 851., 666., 520., 492.,\n",
       "        561., 497., 573., 533., 559., 554., 509., 524., 500., 535., 647.,\n",
       "        707., 745., 720., 742., 814., 708., 615., 625., 463., 413., 852.,\n",
       "        551., 436., 344., 417., 501., 403., 488., 389., 303., 445., 546.,\n",
       "        513., 456., 473., 455., 452., 390., 325., 317., 358., 536., 425.,\n",
       "        222., 364., 473., 461., 485., 547., 611., 501., 505., 515., 489.,\n",
       "        525., 580., 494., 645., 781., 688., 680., 746., 800., 736., 748.,\n",
       "        655., 652., 558., 716., 609., 676., 578., 555., 453., 466., 651.,\n",
       "        614., 549., 494., 407., 681., 646., 677., 558., 644., 525., 581.,\n",
       "        382., 275., 196., 150., 271., 494., 563., 323., 318., 169., 101.,\n",
       "        355., 393., 326., 336., 470., 463., 434., 415., 593., 494., 381.,\n",
       "        399., 420., 359., 502., 399., 123., 157., 167., 103., 227., 173.,\n",
       "        403., 635., 566., 275., 147.,  43., 222., 100., 277., 238., 390.,\n",
       "        442., 276., 321.]),\n",
       " 'tr2': array([212., 419., 556., 579., 693., 242., 636., 581., 581., 576., 515.,\n",
       "        513., 393., 284.,  30.,  72., 234.,  70.,  34., 544., 709., 393.,\n",
       "        498., 523., 584., 705., 718., 721., 729., 784., 507., 163.,  74.,\n",
       "        229., 182., 194., 218.,  31., 288.,  85., 300., 618., 676., 696.,\n",
       "        704., 727., 701., 654., 374., 103., 179., 216.,  62., 346., 557.,\n",
       "        601., 511., 545., 588., 570., 355.,  43.,   1., 111., 375., 207.,\n",
       "        225., 236., 121., 191.,  93.,   7.,  14., 233.,  32., 105., 224.,\n",
       "        348., 165., 122., 200., 326., 266., 339., 182., 232.,  28., 116.,\n",
       "        230., 273., 410., 378., 304.,  45., 140., 402., 645., 693., 331.,\n",
       "        122.,  50., 282., 519., 565., 719., 526., 342., 301.,  82., 118.,\n",
       "        230., 301., 477., 590., 465., 457., 162.,  84., 200., 282., 111.,\n",
       "        243., 308., 599., 673., 655., 743., 633., 779., 583., 566., 295.,\n",
       "        393., 302., 110.,  51.,  59., 288., 295., 371., 535., 505., 621.,\n",
       "        742., 758., 667., 652., 759., 600., 515., 628., 795., 552., 424.,\n",
       "        260., 391., 160., 214.,  86., 139., 640., 758., 759., 683., 804.,\n",
       "        635., 412., 150.,  96., 177., 376., 486., 464., 401., 111., 177.,\n",
       "        601.]),\n",
       " 'tr3': array([622., 494., 486., 389., 464., 686., 827., 508., 501., 687., 667.,\n",
       "        667., 713., 644., 474., 471., 215., 731., 564., 806., 429., 545.,\n",
       "        413., 456., 520., 454., 464., 474., 605., 543., 539., 464., 420.,\n",
       "        519., 486., 348., 815., 619., 610., 385., 576., 364., 233., 791.,\n",
       "        520., 476., 515., 432., 478., 484., 697., 682., 457., 576., 729.,\n",
       "        746., 541., 798., 513., 713., 659., 634., 705., 654., 700., 755.,\n",
       "        637., 556., 553., 159., 427., 570., 867., 613., 695., 913., 746.,\n",
       "        807., 767., 757., 525., 755., 757., 732., 698., 665., 658., 681.,\n",
       "        720., 756., 763., 732., 795., 715., 732., 752., 720., 749., 757.,\n",
       "        701., 767., 745., 748., 715., 599., 590., 524., 749., 686., 707.,\n",
       "        761., 716., 644., 711., 721., 551., 547., 586., 648., 672., 758.,\n",
       "        591., 735., 777., 747., 642., 750., 747., 752., 776., 718., 609.,\n",
       "        449., 330., 696., 771., 751., 754., 819., 725., 661., 714., 739.,\n",
       "        733., 656., 786., 743., 760., 742., 866., 843., 835.]),\n",
       " 'tr4': array([559., 562., 466., 477., 515., 504., 678., 694., 523., 673., 740.,\n",
       "        676., 602., 464., 572., 257., 662., 519., 396., 258., 597., 580.,\n",
       "        587., 611., 545., 439., 534., 672., 729., 644., 681., 567., 265.,\n",
       "        686., 798., 755., 401.,  42., 744., 160., 692., 716., 734., 632.,\n",
       "        701., 638., 466., 752., 540., 531., 393., 226., 629., 410., 418.,\n",
       "        463., 640., 565., 526., 525., 297., 416., 539., 582., 493., 621.,\n",
       "        443., 497., 555., 516., 455., 520., 496., 672., 587., 350., 211.,\n",
       "        398.,  57., 539., 540., 449., 413., 449., 666., 246., 636., 594.,\n",
       "        673., 669., 760., 278., 508., 642., 820., 309., 313., 539., 636.,\n",
       "        601., 644., 490., 588., 507., 673., 511., 447., 562., 349., 351.,\n",
       "        584., 569., 502., 252., 639., 389., 358., 307.,  89., 666., 661.,\n",
       "        578., 540., 625., 664., 484., 485., 507., 647., 440., 517., 471.,\n",
       "        474., 475., 569., 644., 610., 460., 554., 576., 552., 214., 596.,\n",
       "        481., 326., 662., 630.]),\n",
       " 'tr5': array([602., 366., 341., 398., 533., 483., 582., 524., 422., 498., 545.,\n",
       "        571., 627., 711., 348.,  42., 345., 497., 538., 681., 555., 482.,\n",
       "        483., 466., 305., 423., 412., 536., 554., 550., 663., 505., 581.,\n",
       "        585., 504., 501., 504., 459., 401., 316.,  28., 160., 249., 491.,\n",
       "        513., 501., 574., 586., 474., 534., 504., 365., 520., 444., 442.,\n",
       "        475., 512., 487., 416.,  81., 636., 651., 423.,  37., 357., 520.,\n",
       "        643., 708., 624., 649., 602., 461., 605., 131.,  28., 378., 476.,\n",
       "        524., 620., 593., 690., 637., 356., 412., 425., 483., 519., 540.,\n",
       "        378., 409., 520., 672., 776., 773., 593., 245., 133., 109.,  78.,\n",
       "        234., 233., 412., 481., 503., 483., 532., 503., 276.,  47., 335.,\n",
       "        351., 554., 566., 494., 260., 230., 104., 193., 469., 483., 432.,\n",
       "        342., 397., 409., 451., 494., 433., 481., 501., 511., 546., 279.,\n",
       "        384., 297., 300., 157.,  54., 372., 503., 534., 516., 571., 382.,\n",
       "         72., 113., 558., 480., 602., 407., 464., 421., 457., 449., 403.,\n",
       "        485., 457., 448., 593., 483., 420.,  43., 265.,  78., 431., 423.,\n",
       "        474., 475., 486.,  15., 158., 411., 408., 496., 549., 815., 178.,\n",
       "        356.]),\n",
       " 'tr6': array([680., 570., 384., 580., 536., 392., 230., 154., 366., 627., 372.,\n",
       "        257.,  43., 174., 141., 220., 169., 431., 663., 507., 618., 484.,\n",
       "        376.,  11., 178., 298., 619., 494., 181., 125., 231., 398., 388.,\n",
       "        549., 240.,  58.,  87., 273., 461., 539., 389., 172., 151., 419.,\n",
       "        494., 465., 292.,   2., 284., 464., 537., 482., 391., 195.,  61.,\n",
       "        204., 390., 589., 501., 377., 102.,  20., 132., 399., 407., 258.,\n",
       "        399., 523., 482., 594., 491., 129., 290., 281., 652., 421., 251.,\n",
       "        113., 120., 346., 419., 643., 461., 475., 155., 107., 370., 513.,\n",
       "         36., 209., 328., 417.,  99.,  84., 326., 635., 442., 266.,  67.,\n",
       "        179., 230., 587., 423., 650., 320., 422., 137., 158., 231., 676.,\n",
       "        540., 549., 155.,  61., 461., 516., 473., 227.,  50.,   5.,  82.,\n",
       "        122., 360., 451., 614., 526., 466., 351.,  68., 137., 163., 224.,\n",
       "        584., 544., 399., 358., 276.,  15.,  78., 611., 436., 316.,  28.,\n",
       "        139., 255., 398., 424., 524., 563., 594., 569., 362.,  46., 211.,\n",
       "        147., 165., 400., 589., 567., 510., 147., 284.]),\n",
       " 'tr7': array([647., 714., 582., 751., 742., 756., 511., 418., 678., 435., 409.,\n",
       "        193., 598., 615., 659., 702., 622., 359., 666., 709., 583., 460.,\n",
       "        533., 619., 480., 458., 502., 587., 596., 527., 522., 583., 535.,\n",
       "        296., 553., 605., 595., 596., 564., 492., 530., 390., 411., 608.,\n",
       "        591., 578., 603., 482., 468., 651., 650., 433., 613., 502., 655.,\n",
       "        573., 516., 493., 598., 637., 404., 349., 498., 239., 320., 966.,\n",
       "        583., 606., 708., 647., 764., 533., 484., 396., 470., 476., 537.,\n",
       "        598., 565., 690., 442., 571., 634., 486., 718., 502., 567., 674.,\n",
       "        610., 638., 508., 405., 567., 542., 612., 426., 561., 555., 579.,\n",
       "        497., 648., 575., 654., 636., 573., 588., 512., 526., 463., 509.,\n",
       "        567., 493., 541., 425., 340., 269., 313., 266., 590., 428., 539.,\n",
       "        288., 519., 347., 314., 109., 370., 334., 334., 242.,  27., 201.,\n",
       "        539., 575., 551., 548., 417., 497., 385., 551., 436., 229., 527.,\n",
       "        434., 309., 401., 390., 470., 608., 599.]),\n",
       " 'tr8': array([428., 740., 668., 722., 757., 789., 731., 746., 783., 850., 812.,\n",
       "        932., 889., 738., 750., 857., 576., 791., 751., 759., 656., 639.,\n",
       "         76., 744., 522., 457., 496., 551., 483., 663., 524., 501., 414.,\n",
       "        412., 684., 379., 613., 641., 272., 654., 469., 460., 525., 535.,\n",
       "        545., 542., 546., 518., 533., 476., 432., 349., 543., 397., 392.,\n",
       "         28., 125., 648., 430., 367., 501., 558., 265., 229.,  36., 569.,\n",
       "        150., 415., 303., 254., 592., 480., 554., 655., 651., 520., 369.,\n",
       "        467., 256., 333., 412., 437., 557., 593., 567., 641., 491., 469.,\n",
       "        436., 463., 656., 492., 471., 463., 323., 266., 272., 430., 380.,\n",
       "        108., 526., 285., 300.,  54., 565., 464., 510., 373., 398., 299.,\n",
       "        425., 437., 468., 278., 352., 392., 733., 479., 351., 128., 311.,\n",
       "        625., 716., 429., 658., 635., 390., 123., 409., 328., 358., 139.,\n",
       "        361., 278., 606., 479., 341., 435., 720., 522., 275.,  57., 289.,\n",
       "        642., 720., 727.]),\n",
       " 'tr9': array([455., 667., 440., 662., 583., 508., 324., 474., 652., 714., 577.,\n",
       "        462., 511., 660., 727., 788., 220., 688., 480., 487., 439., 338.,\n",
       "        552., 274., 342., 315., 578., 451., 570., 543., 329., 483., 555.,\n",
       "        591., 460., 588., 353., 450., 493., 521., 509., 460., 422., 311.,\n",
       "        233., 433., 435., 451., 260., 207., 143., 290., 489., 477., 473.,\n",
       "        383., 534., 504., 615., 177., 474., 507., 532., 556., 450., 613.,\n",
       "        580., 546., 461., 426., 514., 427., 649., 403., 317., 538., 556.,\n",
       "        508., 510., 446., 512., 575., 573., 535., 556., 586., 506., 563.,\n",
       "        524., 493., 553., 411., 379., 397., 444., 364., 498., 345., 348.,\n",
       "        621., 417., 260., 205., 220., 576., 624., 528., 587., 462., 501.,\n",
       "        399., 468., 383., 531., 478., 474., 587., 465., 613., 411., 412.,\n",
       "        620., 497., 379., 242., 189.,  20., 465., 374., 462., 556., 334.,\n",
       "        426., 684., 357., 698., 583., 546., 620., 546., 528., 514., 558.,\n",
       "        527., 622., 543., 540., 553., 621., 604., 449., 516., 560., 410.,\n",
       "        339., 354., 480., 398., 588.]),\n",
       " 'tr10': array([ 61., 427., 509., 660., 326.,  24., 521., 203., 336., 546., 527.,\n",
       "        637., 685., 560., 583., 494., 416., 208.,  88., 224., 689., 574.,\n",
       "        678., 221., 157., 377., 407., 501., 543., 451., 388., 394., 244.,\n",
       "        951., 564., 381., 538., 279., 223., 902., 838., 706., 604., 261.,\n",
       "        268., 262., 278., 293., 450., 392., 176., 109., 308., 393., 198.,\n",
       "        104.,  78.,  43., 163.,  18.,  22.,  95., 232., 173., 302., 448.,\n",
       "        203., 177., 176.,  68.,  41., 118.,  23.,  74.,  29., 153., 156.,\n",
       "         60., 295., 164., 216., 360., 369., 436., 346., 336., 221., 193.,\n",
       "        158., 198., 115.,  14., 110., 204., 110., 147., 188.,  17., 230.,\n",
       "        108.,   9.,  31.,   1.,  73., 125., 226., 265., 488., 501., 508.,\n",
       "        539., 219.,   4.,   5., 166., 205., 185.,  18.,  34.,   8.,  68.,\n",
       "        259., 151., 101.,  48., 213.,  73., 100.,  11.,  33.,  48., 158.,\n",
       "        125.,  32.,  65.,  85., 113.,  97., 138., 250., 120., 232., 614.,\n",
       "        459., 453., 443., 357., 233.,  71.,   7.,  99., 173., 290.,  78.,\n",
       "         27.,  12., 182., 237.,  66., 297., 433., 584., 218.,  31., 166.,\n",
       "         79.,  25., 143.,  90.,  69.,  66., 260., 316., 170., 235., 309.,\n",
       "        309.]),\n",
       " 'tr11': array([569., 205.,  99.,  51., 194., 121., 306., 125.,  70.,  52.,  39.,\n",
       "        190., 152., 132., 239., 348., 431., 548., 391., 173., 345., 579.,\n",
       "        372., 202.,   5., 136., 297.,  72.,  39., 253., 573., 519., 367.,\n",
       "        189.,  98.,  50.,  83., 120., 224., 369., 477., 521., 489., 271.,\n",
       "        172., 254., 547., 493., 226.,   5., 251., 558., 513., 363.,  19.,\n",
       "        140., 243., 387., 456., 398., 135., 133., 420., 378., 403., 588.,\n",
       "        282., 138.,  77., 166., 283., 443.,  39., 201., 348., 334., 112.,\n",
       "        533.,  61., 552., 229., 110.,  69., 564., 218., 135., 472.,  50.,\n",
       "        303., 327., 288., 507.,  49., 323., 464., 195., 243., 476., 241.,\n",
       "         59., 291., 354., 406.,  31., 378., 469., 551., 606., 212., 105.,\n",
       "        334., 535., 650., 552., 618., 463., 523., 469., 154.,  56., 168.,\n",
       "        346., 307., 254.,   7.,  32., 102.,  26.,  42.,  10.,  57., 550.,\n",
       "        633., 494., 218., 131.,  15., 198.,  25., 293., 555., 536., 432.,\n",
       "        202.,  40., 336., 501., 446., 155.,  77., 296., 349., 162.]),\n",
       " 'tr12': array([738., 681., 825., 820., 828., 916., 787., 618., 589., 317., 276.,\n",
       "        405., 379., 486., 289., 407., 480., 468., 571., 500., 573., 484.,\n",
       "        489., 395., 319., 387., 267., 677., 723., 664., 489., 123., 830.,\n",
       "        615., 358., 347., 803., 701., 563., 611., 545., 576., 337., 242.,\n",
       "         46.,  20., 729., 710., 686., 574., 723., 552., 376.,  39., 185.,\n",
       "        373., 648., 664., 430., 612., 719., 734., 508., 321., 664., 608.,\n",
       "        496., 243., 114., 248.,  11., 710., 651., 507., 405., 817., 477.,\n",
       "        462., 608., 606., 498., 450., 404., 639., 511., 534., 347., 511.,\n",
       "        397., 464., 402., 368., 294., 524., 448., 425., 399., 393., 217.,\n",
       "        152., 134., 230., 670., 731., 707., 499., 543., 664., 607., 291.,\n",
       "         88., 285., 523., 112., 657., 483., 485., 165., 631., 222., 733.,\n",
       "        255., 818., 564., 662., 436., 395., 546., 498., 448., 433.,  78.,\n",
       "        408., 481., 201., 670.,  99., 659., 371., 237., 729., 461., 248.])}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220713\n",
      "20220721\n",
      "20220804\n",
      "20220808\n",
      "20220810\n",
      "20220811\n",
      "20220815\n",
      "20220816\n",
      "20221003\n",
      "2022100401\n",
      "2022100402\n",
      "20221005\n"
     ]
    }
   ],
   "source": [
    "import hdf5storage\n",
    "\n",
    "ses12_errors=[]\n",
    "\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    ses12_errors.append(errors[folder])\n",
    "\n",
    "ses12_errors.append(folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the list to an object array (equivalent to MATLAB cell array)\n",
    "ses12_errors_cell_array = np.empty(len(ses12_errors), dtype=object)\n",
    "# Fill the object array with the data\n",
    "for idx, arr in enumerate(ses12_errors):\n",
    "    ses12_errors_cell_array[idx] = arr\n",
    "# Save the object array (cell-like structure) to a .mat file\n",
    "hdf5storage.savemat('ses12_errors.mat', {'cell_data': ses12_errors_cell_array}, format='7.3')\n",
    "    \n",
    "# 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('errors.mat',errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('errors.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237., 200.,  73.,  72.,  61.,  35., 175.,  87., 124.,  74., 102.,\n",
       "       152., 205.,  75., 149.,  63.,  22.,  22.,  40.,  24.,  32.,  83.,\n",
       "       113.,  74.,  27.,   0.,  43.,  23., 103.,  73.,  51.,  45.,  61.,\n",
       "         3.,   8.,  23., 131., 108.,  87.,  13., 385., 353., 289., 244.,\n",
       "       333., 123.,  73.,  63.,  72.,  22.,   3.,  19.,   6.,  37.,  31.,\n",
       "        49.,  75.,  78.,  21.,  48.,  29.,  97., 109., 142.,  78., 321.,\n",
       "       203., 233.,  22.,   2., 169., 148.,  75.,  61.,  40.,  37.,  24.,\n",
       "        66.,  32.,  15.,  52.,  18., 134., 139., 131., 145.,  24.,  20.,\n",
       "        10., 103.,   1., 124.,   8.,  83., 142.,  70.,  71.,   2.,  93.,\n",
       "       141.,  53.,  43., 161., 185.,  48.,  60.,  95.,  69., 120., 212.,\n",
       "         2.,   3.,  53.,  53., 150., 236., 249., 185., 241., 219., 217.,\n",
       "       124.,  62., 233., 445., 211.,  94.,  28.,  34.,  64., 234., 194.,\n",
       "       185., 201., 302., 323., 453., 473., 198., 153., 168.,   9.,  93.,\n",
       "        11., 116.,  48., 216., 120., 245.,   8.,  31.,  64., 109., 195.,\n",
       "       142., 114., 165., 121., 274.,   7.,  93.,  68.,  59.,  57.,  27.,\n",
       "        58.,  17.,  31.,  61., 286., 324., 451., 171., 170., 251., 174.,\n",
       "        80., 137.,  37., 183., 151., 129., 171., 280., 169., 141.,  67.,\n",
       "       131., 178., 261., 176., 273., 155., 170., 146., 269., 304.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdict['20220713']['tr1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
