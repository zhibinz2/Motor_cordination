{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import rqa_functions as rqa\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220721_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220713_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220816_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220810_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220804_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20221005_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_2022100401_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220815_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20221003_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_2022100402_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220808_distances.pkl\n",
      "/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/dyad_20220811_distances.pkl\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where the files are located\n",
    "# directory_path = \"/data/Italo/correlation_distances\"\n",
    "directory_path = \"/ssd/zhibin/1overf/Cleaned_sourcedata/cortical_source_data/taplocked/correlation_distances/\"\n",
    "\n",
    "# List all files and directories in the specified path\n",
    "all_items = os.listdir(directory_path)\n",
    "\n",
    "# Filter out files that start with \"dyad_20\"\n",
    "matching_files = [filename for filename in all_items if filename.startswith(\"dyad_20\")]\n",
    "\n",
    "# Optionally, get the full paths if needed\n",
    "full_paths = [os.path.join(directory_path, filename) for filename in matching_files]\n",
    "\n",
    "# Print the list of matching file paths\n",
    "for file_path in full_paths:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices_to_eliminate(subj1, subj2):\n",
    "    \"\"\"\n",
    "    Calculate the indices to be eliminated based on the differences in trial data points\n",
    "    for two subjects, ensuring that only the necessary data points are removed to align their sizes.\n",
    "\n",
    "    Parameters:\n",
    "    - list_indices_subj1: Numpy array of trial sizes for subject 1\n",
    "    - list_indices_subj2: Numpy array of trial sizes for subject 2\n",
    "\n",
    "    Returns:\n",
    "    - index_to_eliminate_subj1: Indices to eliminate from subject 1 to align with subject 2\n",
    "    - index_to_eliminate_subj2: Indices to eliminate from subject 2 to align with subject 1\n",
    "    \"\"\"\n",
    "\n",
    "    list_indices_subj1 = np.array([i[1] for i in subj1])\n",
    "    list_indices_subj2 = np.array([i[1] for i in subj2])\n",
    "\n",
    "    cumsum_subj1 = [sum([x[1] for x in subj1[:i+1]]) for i in range(len(subj1))]\n",
    "    cumsum_subj2 = [sum([x[1] for x in subj2[:i+1]]) for i in range(len(subj2))]\n",
    "\n",
    "    index_differences_sub1 = list_indices_subj1 - list_indices_subj2\n",
    "    index_differences_sub2 = list_indices_subj2 - list_indices_subj1\n",
    "\n",
    "    index_to_eliminate_subj1 = []\n",
    "    for i,n_points in enumerate(index_differences_sub1):\n",
    "        if n_points>0:\n",
    "            indexes = [j for j in range(cumsum_subj1[i]-index_differences_sub1[i],cumsum_subj1[i])]\n",
    "            index_to_eliminate_subj1.extend(indexes)\n",
    "\n",
    "    index_to_eliminate_subj2 = []\n",
    "    for i,n_points in enumerate(index_differences_sub2):\n",
    "        if n_points>0:\n",
    "            indexes = [j for j in range(cumsum_subj2[i]-index_differences_sub2[i],cumsum_subj2[i])]\n",
    "            index_to_eliminate_subj2.extend(indexes)\n",
    "\n",
    "    return index_to_eliminate_subj1[::-1], index_to_eliminate_subj2[::-1]\n",
    "\n",
    "def session_data_loading(file_path):\n",
    "\n",
    "    session = (file_path.split('/')[-1]).split('_')[1]\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Load the object from the pickle file\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    subj1 = data['subj1']['sizes']\n",
    "    subj2 = data['subj2']['sizes']\n",
    "\n",
    "    index_to_eliminate_subj1, index_to_eliminate_subj2 = find_indices_to_eliminate(subj1, subj2)\n",
    "\n",
    "    file_order_size = []\n",
    "    for i in range(len(subj1)):\n",
    "        file_sub1,len_1 = subj1[i]\n",
    "        file_sub2,len_2 = subj2[i]\n",
    "        if len_1 < len_2:\n",
    "            file_order_size.append((file_sub1,file_sub2,len_1))\n",
    "        else:\n",
    "            file_order_size.append((file_sub1,file_sub2,len_2))\n",
    "\n",
    "    mat1 = data['subj1']['distances']\n",
    "    for index in index_to_eliminate_subj1:\n",
    "        mat1 = np.delete(np.delete(mat1, index, axis=0), index, axis=1)\n",
    "\n",
    "    mat2 = data['subj2']['distances']\n",
    "    for index in index_to_eliminate_subj2:\n",
    "        mat2 = np.delete(np.delete(mat2, index, axis=0), index, axis=1)\n",
    "\n",
    "    trial_len = [i[2] for i in file_order_size]\n",
    "    start_points = list(np.cumsum(trial_len))\n",
    "    end_points = [i-1 for i in start_points]\n",
    "    start_points.insert(0,0)\n",
    "    start_points.pop(-1)\n",
    "    #print(start_points)\n",
    "    #print(end_points)\n",
    "    start_stop = list(zip(start_points,end_points))\n",
    "    #print(start_stop)\n",
    "\n",
    "    condition_dictionary = {1: 'Uncoupled', 2: '1_lead', 3: '2_lead', 4: 'Mutual'}\n",
    "    type_dictionary = {1: 'Synchronization', 2: 'Syncopation'}\n",
    "\n",
    "    # Initialize an empty list to store each row's data as a dictionary\n",
    "    data = []\n",
    "\n",
    "    for i, entry in enumerate(file_order_size):\n",
    "        session = entry[0].split('/')[0]\n",
    "        trial = entry[0].split('_')[2][:-4]\n",
    "        length = entry[2]\n",
    "        start, stop = start_stop[i]\n",
    "        # filename = '/data/Italo/finger_tapping_behavioral_data/clean_' + str(session) + '_bpchan.mat'\n",
    "        filename = '/home/zhibinz2/Documents/GitHub/finger_tapping_behavioral_data/clean_' + str(session) + '_bpchan.mat'\n",
    "        beh_data = loadmat(filename)\n",
    "        conditions = list(beh_data['conditions'][0])\n",
    "        condition = condition_dictionary[conditions[int(trial)-1]]\n",
    "        session_type = type_dictionary[beh_data['session'][0][0]]\n",
    "\n",
    "        # Instead of printing, store the data in a dictionary\n",
    "        row_data = {\n",
    "            'session': session,\n",
    "            'session_type': session_type,\n",
    "            'condition': condition,\n",
    "            'trial': trial,\n",
    "            'start': start,\n",
    "            'stop': stop\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    metadata = pd.DataFrame(data)\n",
    "    session_data = {'Subject 1': mat1,\n",
    "                    'Subject 2': mat2,\n",
    "                    'Metadata': metadata,\n",
    "                    'Session Type': session_type}\n",
    "    return session, session_data\n",
    "\n",
    "def transform_tuples_to_symbols(tuple_sequence):\n",
    "    \"\"\"\n",
    "    Transforms a sequence of tuples into a sequence of unique symbols (integer numbers).\n",
    "    \n",
    "    Parameters:\n",
    "    - tuple_sequence: A sequence (e.g., list) of tuples.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of integers representing the sequence of symbols.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a mapping from each unique tuple to a unique integer\n",
    "    unique_tuples = set(tuple_sequence)  # Find all unique tuples\n",
    "    tuple_to_symbol_map = {t: i for i, t in enumerate(unique_tuples)}\n",
    "    \n",
    "    # Step 2: Transform the original sequence of tuples using the map\n",
    "    symbol_sequence = [tuple_to_symbol_map[t] for t in tuple_sequence]\n",
    "    \n",
    "    return symbol_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = {}\n",
    "for file_path in full_paths:\n",
    "    session,data = session_data_loading(file_path)\n",
    "    session_data[session] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['20220721', '20220713', '20220816', '20220810', '20220804', '20221005', '2022100401', '20220815', '20221003', '2022100402', '20220808', '20220811'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file(filename):\n",
    "    \"\"\"\n",
    "    Load a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The path to the pickle file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    - The Python object loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' was not found.\")\n",
    "    except EOFError:\n",
    "        print(f\"Error: The file '{filename}' may be corrupted or empty.\")\n",
    "    except pickle.UnpicklingError:\n",
    "        print(f\"Error: The file '{filename}' could not be unpickled. It may not be a valid pickle file or may be corrupted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "session_clusterings = load_pickle_file('./clustering_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['20220721', '20220713', '20220816', '20220810', '20220804', '20221005', '2022100401', '20220815', '20221003', '2022100402', '20220808', '20220811'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_clusterings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1985)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(session_clusterings['20220721'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>Session Type</th>\n",
       "      <th>Condition</th>\n",
       "      <th>vmean</th>\n",
       "      <th>vvar</th>\n",
       "      <th>dmean</th>\n",
       "      <th>dvar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.137778</td>\n",
       "      <td>0.118795</td>\n",
       "      <td>2.103896</td>\n",
       "      <td>0.093102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Uncoupled</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.089958</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>2.118012</td>\n",
       "      <td>0.116508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Uncoupled</td>\n",
       "      <td>2.332046</td>\n",
       "      <td>0.221792</td>\n",
       "      <td>2.119403</td>\n",
       "      <td>0.105146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.107612</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>2.991870</td>\n",
       "      <td>29.487739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.238477</td>\n",
       "      <td>0.181606</td>\n",
       "      <td>2.181250</td>\n",
       "      <td>0.248398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.203980</td>\n",
       "      <td>0.162372</td>\n",
       "      <td>2.145161</td>\n",
       "      <td>0.156348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Session Session Type        Condition     vmean      vvar     dmean  \\\n",
       "0    20220721  Syncopation  Leader-Follower  2.033333  0.032222  2.083333   \n",
       "1    20220721  Syncopation  Leader-Follower  2.137778  0.118795  2.103896   \n",
       "2    20220721  Syncopation           Mutual  2.000000  0.000000  2.040000   \n",
       "3    20220721  Syncopation        Uncoupled  2.000000  0.000000  2.000000   \n",
       "4    20220721  Syncopation  Leader-Follower  2.000000  0.000000  2.000000   \n",
       "..        ...          ...              ...       ...       ...       ...   \n",
       "139  20220811  Syncopation           Mutual  2.089958  0.081866  2.118012   \n",
       "140  20220811  Syncopation        Uncoupled  2.332046  0.221792  2.119403   \n",
       "141  20220811  Syncopation           Mutual  2.107612  0.096031  2.991870   \n",
       "142  20220811  Syncopation  Leader-Follower  2.238477  0.181606  2.181250   \n",
       "143  20220811  Syncopation  Leader-Follower  2.203980  0.162372  2.145161   \n",
       "\n",
       "          dvar  \n",
       "0     0.076389  \n",
       "1     0.093102  \n",
       "2     0.038400  \n",
       "3     0.000000  \n",
       "4     0.000000  \n",
       "..         ...  \n",
       "139   0.116508  \n",
       "140   0.105146  \n",
       "141  29.487739  \n",
       "142   0.248398  \n",
       "143   0.156348  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "recurrence_plots = {}\n",
    "\n",
    "for session_code in session_data:\n",
    "    mat1,mat2,metadata,session_type =  session_data[session_code].values()\n",
    "    sub1_seq,sub2_seq = session_clusterings[session_code]\n",
    "    joint_seq = list(zip(sub1_seq,sub2_seq))\n",
    "    joint_seq = transform_tuples_to_symbols(joint_seq)\n",
    "\n",
    "    start_list = list(metadata['start'])\n",
    "    stop_list = list(metadata['stop'])\n",
    "    start_stop = list(zip(start_list,stop_list))\n",
    "    conditions = list(metadata['condition'])\n",
    "\n",
    "    recurrence_matrix = rqa.build_rp(joint_seq)\n",
    "    recurrence_plots[session_code] = {'rp': recurrence_matrix,\n",
    "                                      'symbol_sequence': joint_seq}\n",
    "    for j,indices in enumerate(start_stop):\n",
    "        condition = conditions[j]\n",
    "        if condition == '1_lead' or condition == '2_lead':\n",
    "            condition = 'Leader-Follower'\n",
    "        start, stop = indices\n",
    "        \n",
    "        matrix = recurrence_matrix[start:stop,start:stop]\n",
    "\n",
    "        vlines = rqa.find_lines(matrix, min_len=2, direction='vertical')\n",
    "        vmean = np.mean(vlines)\n",
    "        vvar = np.var(vlines)\n",
    "        dlines = rqa.find_lines(matrix, min_len=2, direction='diagonal')\n",
    "        dmean = np.mean(dlines)\n",
    "        dvar = np.var(dlines)\n",
    "\n",
    "        df_row = {'Session': session_code,\n",
    "                'Session Type': session_type,\n",
    "                'Condition': condition,\n",
    "                'vmean': vmean,\n",
    "                'vvar': vvar,\n",
    "                'dmean': dmean,\n",
    "                'dvar': dvar}\n",
    "        data.append(df_row)\n",
    "\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rp', 'symbol_sequence'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recurrence_plots['20220713'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2268, 2268)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(recurrence_plots['20220713']['rp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2268,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(recurrence_plots['20220713']['symbol_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>Session Type</th>\n",
       "      <th>Condition</th>\n",
       "      <th>vmean</th>\n",
       "      <th>vvar</th>\n",
       "      <th>dmean</th>\n",
       "      <th>dvar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.137778</td>\n",
       "      <td>0.118795</td>\n",
       "      <td>2.103896</td>\n",
       "      <td>0.093102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Uncoupled</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220721</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.089958</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>2.118012</td>\n",
       "      <td>0.116508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Uncoupled</td>\n",
       "      <td>2.332046</td>\n",
       "      <td>0.221792</td>\n",
       "      <td>2.119403</td>\n",
       "      <td>0.105146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Mutual</td>\n",
       "      <td>2.107612</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>2.991870</td>\n",
       "      <td>29.487739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.238477</td>\n",
       "      <td>0.181606</td>\n",
       "      <td>2.181250</td>\n",
       "      <td>0.248398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>20220811</td>\n",
       "      <td>Syncopation</td>\n",
       "      <td>Leader-Follower</td>\n",
       "      <td>2.203980</td>\n",
       "      <td>0.162372</td>\n",
       "      <td>2.145161</td>\n",
       "      <td>0.156348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Session Session Type        Condition     vmean      vvar     dmean  \\\n",
       "0    20220721  Syncopation  Leader-Follower  2.033333  0.032222  2.083333   \n",
       "1    20220721  Syncopation  Leader-Follower  2.137778  0.118795  2.103896   \n",
       "2    20220721  Syncopation           Mutual  2.000000  0.000000  2.040000   \n",
       "3    20220721  Syncopation        Uncoupled  2.000000  0.000000  2.000000   \n",
       "4    20220721  Syncopation  Leader-Follower  2.000000  0.000000  2.000000   \n",
       "..        ...          ...              ...       ...       ...       ...   \n",
       "139  20220811  Syncopation           Mutual  2.089958  0.081866  2.118012   \n",
       "140  20220811  Syncopation        Uncoupled  2.332046  0.221792  2.119403   \n",
       "141  20220811  Syncopation           Mutual  2.107612  0.096031  2.991870   \n",
       "142  20220811  Syncopation  Leader-Follower  2.238477  0.181606  2.181250   \n",
       "143  20220811  Syncopation  Leader-Follower  2.203980  0.162372  2.145161   \n",
       "\n",
       "          dvar  \n",
       "0     0.076389  \n",
       "1     0.093102  \n",
       "2     0.038400  \n",
       "3     0.000000  \n",
       "4     0.000000  \n",
       "..         ...  \n",
       "139   0.116508  \n",
       "140   0.105146  \n",
       "141  29.487739  \n",
       "142   0.248398  \n",
       "143   0.156348  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "recurrence_plots = {}\n",
    "\n",
    "for session_code in session_data:\n",
    "    mat1,mat2,metadata,session_type =  session_data[session_code].values()\n",
    "    sub1_seq,sub2_seq = session_clusterings[session_code]\n",
    "    joint_seq = list(zip(sub1_seq,sub2_seq))\n",
    "    joint_seq = transform_tuples_to_symbols(joint_seq)\n",
    "\n",
    "    start_list = list(metadata['start'])\n",
    "    stop_list = list(metadata['stop'])\n",
    "    start_stop = list(zip(start_list,stop_list))\n",
    "    conditions = list(metadata['condition'])\n",
    "\n",
    "    recurrence_matrix = rqa.build_rp(joint_seq)\n",
    "    recurrence_plots[session_code] = {'rp': recurrence_matrix,\n",
    "                                      'symbol_sequence': joint_seq}\n",
    "    for j,indices in enumerate(start_stop):\n",
    "        condition = conditions[j]\n",
    "        if condition == '1_lead' or condition == '2_lead':\n",
    "            condition = 'Leader-Follower'\n",
    "        start, stop = indices\n",
    "        \n",
    "        matrix = recurrence_matrix[start:stop,start:stop]\n",
    "\n",
    "        vlines = rqa.find_lines(matrix, min_len=2, direction='vertical')\n",
    "        vmean = np.mean(vlines)\n",
    "        vvar = np.var(vlines)\n",
    "        dlines = rqa.find_lines(matrix, min_len=2, direction='diagonal')\n",
    "        dmean = np.mean(dlines)\n",
    "        dvar = np.var(dlines)\n",
    "\n",
    "        df_row = {'Session': session_code,\n",
    "                'Session Type': session_type,\n",
    "                'Condition': condition,\n",
    "                'vmean': vmean,\n",
    "                'vvar': vvar,\n",
    "                'dmean': dmean,\n",
    "                'dvar': dvar}\n",
    "        data.append(df_row)\n",
    "\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
